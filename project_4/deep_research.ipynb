{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the length, we can use the formula for the perimeter of a rectangle: P = 2l + 2w, where P is the perimeter, l is the length, and w is the width.\n",
      "\n",
      "Given that the perimeter is 40 cm and the width is 5 cm, we can plug these values into the formula:\n",
      "\n",
      "40 = 2l + 2(5)\n",
      "40 = 2l + 10\n",
      "40 - 10 = 2l\n",
      "\n",
      "30 = 2l\n",
      "15 = l\n",
      "\n",
      "So, the length of the rectangle is 15 cm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYOUR CODE HERE (~10 lines of code)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Write a few examples showing reasoning steps\n",
    "# Step 2: Write your new question\n",
    "# Step 3: Concatenate examples + new question into a single prompt\n",
    "# Step 4: Call your Ollama or OpenAI client to get a response from llama3.2:3b # e.g., client.chat.completions.create(...)\n",
    "# Step 5: Print the final answer\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "few_shot_examples = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "question = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "\n",
    "prompt = few_shot_examples + f\"\\nQ: {question}\\nA:\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama'\n",
    "    )\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.9\n",
    ")   \n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\"\"\"\n",
    "YOUR CODE HERE (~10 lines of code)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface (https://huggingface.co/docs/transformers/en/model_doc/gpt2)\n",
    "# Step 2: Write 1–2 few-shot reasoning examples (short, explicit steps + final answer in your own unique format)\n",
    "# Step 3: Append a new test question after the examples to form one prompt string\n",
    "# Step 4: Generate 1–3 completions with different decoding settings (e.g., greedy vs. top-k)\n",
    "# Step 5: Print raw outputs; check if steps are followed and if the final answer is correct\n",
    "\n",
    "# MPS setup for Mac with Apple Silicon\n",
    "# code enables and selects Apple’s GPU backend for PyTorch (MPS = Metal Performance Shaders) \n",
    "# so tensors / models run on Apple Silicon GPUs.\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\" #  allow unsupported MPS ops to fall back to CPU instead of failing (useful for compatibility).\n",
    "assert torch.backends.mps.is_available(), \"MPS backend is not available on this system.\" # check MPS support is present (raises if not).\n",
    "torch.mps.empty_cache()  # clear any cached memory from previous MPS operations.\n",
    "device = torch.device(\"mps\")  # create a device object you can use with .to(device) to move tensors/models to the MPS device.\n",
    "# Why: because running on Apple's GPU (MPS) usually gives much faster inference/training and lower CPU/energy use on Apple Silicon than running entirely on the CPU.\n",
    "\n",
    "pipe = pipeline('text-generation', dtype=torch.float16, model=\"openai-community/gpt2\", device=device)\n",
    "\n",
    "few_shot = \"\"\"Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
    "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
    "\n",
    "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
    "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
    "\"\"\"\n",
    "\n",
    "q = \"A rectangle has perimeter 40 cm and width 5 cm. What is its length?\"\n",
    "prompt = few_shot + f\"\\nQ: {q}\\nA:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152d223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding output:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "\n",
      "A: The rectangle is 40 cm x 5 cm.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n"
     ]
    }
   ],
   "source": [
    "# Greedy decoding\n",
    "out_greedy = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=128, \n",
    "    do_sample=False, # it disables sampling and uses deterministic decoding (greedy or beam search).\n",
    "                     # When False, the model always selects the token with the highest probability at each step.\n",
    "                     # sampling params (temperature, top_k, top_p) are ignored.\n",
    "                     # do_sample=True enables stochastic decoding so temperature, top_k, top_p control diversity.\n",
    "    use_cache=False\n",
    "    )[0]['generated_text']\n",
    "\n",
    "print(\"Greedy decoding output:\\n\", out_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc684f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-p sampling output:\n",
      " Q: If it is 3 PM in London (UTC+0), what time is it in New York (UTC-5)?\n",
      "A: London is 5 hours ahead, so we subtract 5. The final answer is 10 AM.\n",
      "\n",
      "Q: A tank holds 60 L of water. It leaks 3 L per hour and is filled at 5 L per hour. How much water after 4 h?\n",
      "A: Net fill = 5-3 = 2 L/h. 2x4 = 8 L. The final answer is 68 L.\n",
      "\n",
      "Q: A rectangle has perimeter 40 cm and width 5 cm. What is its length?\n",
      "A: The diameter is 6.6 cm and the diameter is 9.6 cm. The height is 12.6 cm.\n",
      "\n",
      "Q: Does the cube have a diameter of 12.6 cm?\n",
      "\n",
      "A: The diameter is 12.6 cm and the diameter is 9.6 cm. The height is 12.6 cm.\n",
      "\n",
      "Q: Is the cube spherical?\n",
      "\n",
      "A: The diameter is 1.4 mm and the diameter is 1.4 mm.\n",
      "\n",
      "Q: Is it circular?\n",
      "\n",
      "A: The diameter is 2.4 mm and the diameter is 2.4 mm.\n",
      "\n",
      "Q\n"
     ]
    }
   ],
   "source": [
    "out_sample = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,  # enables stochastic decoding so temperature, top_k, top_p control diversity.\n",
    "    top_p=0.9,    # nucleus sampling: consider only tokens with cumulative prob mass of 0.9\n",
    "    temperature=0.8,  # higher temp = more random; lower temp = more focused\n",
    "    use_cache=False\n",
    "    )[0]['generated_text']      \n",
    "\n",
    "print(\"\\nTop-p sampling output:\\n\", out_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To understand why neural networks are used to build Large Language Models (LLMs), let's break down the process step by step:\n",
      "\n",
      "1. **Understanding the Problem**: The primary goal of building an LLM is to create a model that can generate human-like text, answer questions, or perform other natural language processing tasks.\n",
      "\n",
      "2. **Traditional Approaches**: Before neural networks, traditional approaches to NLP involved rule-based systems and statistical models. These methods were limited in their ability to handle complex linguistic structures and nuances of human language.\n",
      "\n",
      "3. **The Rise of Neural Networks**: In the 1980s and 1990s, researchers began exploring the use of neural networks for NLP tasks. The key innovation was the development of recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, which allowed models to capture sequential dependencies in language.\n",
      "\n",
      "4. **Why Neural Networks?**: Neural networks are particularly well-suited for LLMs because they can:\n",
      "   - Learn complex patterns in language data\n",
      "   - Handle sequential dependencies between words or tokens\n",
      "   - Capture contextual relationships and nuances of human language\n",
      "\n",
      "5. **Key Architectures**: The most common architectures used in LLMs are:\n",
      "   - Recurrent Neural Networks (RNNs)\n",
      "   - Long Short-Term Memory (LSTM) networks\n",
      "   - Transformers, which have become the de facto standard for modern LLMs\n",
      "\n",
      "6. **Why Transformers?**: Transformers revolutionized the field of NLP by introducing self-attention mechanisms, which allow models to weigh the importance of different tokens in a sentence relative to each other. This leads to better performance and more efficient training.\n",
      "\n",
      "7. **Training Large Models**: The availability of large amounts of labeled data (e.g., text corpora) has enabled researchers to train massive neural networks that can capture complex patterns in language. These models are often trained using techniques like masked language modeling, next sentence prediction, or other supervised learning objectives.\n",
      "\n",
      "8. **Advantages of Neural Networks**: The use of neural networks for LLMs offers several advantages:\n",
      "   - Ability to learn from large amounts of data\n",
      "   - Flexibility and adaptability in handling different linguistic tasks\n",
      "   - Potential for significant improvements over traditional NLP approaches\n",
      "\n",
      "In summary, the use of neural networks for building LLMs is driven by their ability to capture complex patterns in language, handle sequential dependencies, and learn from large amounts of data. The development of architectures like RNNs, LSTMs, and transformers has enabled researchers to create models that can generate human-like text or perform other NLP tasks with high accuracy.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Write the question and a zero-shot CoT cue (e.g., \"Let's think step by step.\")\n",
    "# Step 2: Build a single prompt string that includes brief role guidance plus the question\n",
    "# Step 3: Call your Ollama or OpenAI client to get a response from llama3.2:3b  # e.g., client.chat.completions.create(...)\n",
    "# Step 4: Print the chain and the final answer\n",
    "\n",
    "question = \"Why do we use neural network to build LLMs?\"\n",
    "\n",
    "prompt = f\"\"\"You are a knowledgeable tutor. Answer the question. \n",
    "Question: {question}\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Question = \"What is the sum of the first five prime numbers? Let's think step by step.\"\n",
    "# Prompt = f\"You are a helpful assistant that provides step-by-step reasoning.\\n\\nQuestion: {Question}\\nAnswer:\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votes: Counter({'the largest possible integer square root of 144 is 12.': 1, '**': 1, 'the square root of 144 is **6**.': 1, '**the square root of 144 is 12**.': 1, '**The square root of 144 is 12.**': 1})\n",
      "Chosen answer: the largest possible integer square root of 144 is 12.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def cot_answer(question, temperature=1.0):\n",
    "    # Generate a step-by-step reasoning chain for the given question and extract the final answer.\n",
    "    prompt = f\"\"\"Answer the following question with step-by-step reasoning and final answer after **Therefore,**.\n",
    "        Question: {question}\n",
    "        Let's think step by step.\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL, \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    match = re.search(r\"[Tt]herefore,?\\s*(.*)\", content)\n",
    "    return content, match.group(1).strip() if match else None\n",
    "    \n",
    "\n",
    "def self_consistent(question, n=5):\n",
    "    # Run multiple reasoning chains and select the most frequent final answer by majority voting.\n",
    "    answers = []\n",
    "    for _ in range(n):\n",
    "        _, ans = cot_answer(question, temperature=0.9)\n",
    "        answers.append(ans)\n",
    "    counter = collections.Counter(answers)\n",
    "    winner, _ = counter.most_common(1)[0]\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d79439",
   "metadata": {},
   "source": [
    "Votes: Counter({'we have found the only possible factor pair: 12 and 12.': 1, '**The square root of 144 is 12**.': 1, '** the square root of 144 is 12.': 1, 'the square root of 144 is **12**.': 1, '**the square root of 144 is 12.**': 1})\n",
    "\n",
    "Chosen answer: we have found the only possible factor pair: 12 and 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1:\n",
      "To solve this problem, let's use the formula for the perimeter of a rectangle: \n",
      "\n",
      "Perimeter = 2(l + w)\n",
      "\n",
      "Since you mentioned that the rectangle is twice as long as it is wide, let's say the width is 'w'. Then, the length would be '2w' (twice the width).\n",
      "\n",
      "The perimeter is given as 30 cm. So, we can set up an equation:\n",
      "\n",
      "2(2w + w) = 30\n",
      "\n",
      "Combine like terms:\n",
      "4w + 2w = 30\n",
      "6w = 30\n",
      "\n",
      "Divide by 6 on both sides:\n",
      "w = 5\n",
      "\n",
      "Now that we know the width is 5 cm, we can find the length (which is twice the width):\n",
      "Length = 2 * w = 2 * 5 = 10 cm\n",
      "\n",
      "To find the area of a rectangle, use the formula: \n",
      "Area = Length * Width\n",
      "= 10 * 5\n",
      "= 50\n",
      "\n",
      "The area of the rectangle is 50 square centimeters.\n",
      "\n",
      "Draft 2:\n",
      "To solve for the dimensions of the rectangle and then find its area, we can start with the given information that the perimeter is 30 cm.\n",
      "\n",
      "Let's denote the width as 'w'. Since the length is twice the width, the length would be '2w'.\n",
      "\n",
      "Using the formula for the perimeter of a rectangle: Perimeter = 2(l + w), where l represents the length and w represents the width, we can set up an equation:\n",
      "\n",
      "2(2w + w) = 30\n",
      "\n",
      "Combine like terms:\n",
      "4w + 2w = 30\n",
      "6w = 30\n",
      "\n",
      "Divide by 6 on both sides to solve for 'w':\n",
      "w = 5 cm\n",
      "\n",
      "Now that we have found the width, we can easily determine the length:\n",
      "Length = 2 * w = 2 * 5 = 10 cm\n",
      "\n",
      "Finally, to find the area of the rectangle, use the formula: \n",
      "Area = Length * Width\n",
      "= 10 * 5\n",
      "= 50 square centimeters\n",
      "\n",
      "Draft 3:\n",
      "To solve for the dimensions of the rectangle and find its area, we can use the given information that the perimeter is 30 cm.\n",
      "\n",
      "Let's start by setting up an equation based on the formula for the perimeter of a rectangle: Perimeter = 2(l + w), where l represents the length and w represents the width. Since the length is twice the width, the length (l) can be represented as '2w'.\n",
      "\n",
      "Substituting this information into the perimeter formula gives us:\n",
      "30 = 2(2w + w)\n",
      "\n",
      "Simplifying the equation by combining like terms yields:\n",
      "30 = 6w\n",
      "\n",
      "To solve for 'w', we divide both sides of the equation by 6:\n",
      "w = 5 cm\n",
      "\n",
      "Since the length is twice the width, we can now find the length:\n",
      "Length = 2 * w\n",
      "= 2 * 5\n",
      "= 10 cm\n",
      "\n",
      "Finally, to find the area of the rectangle, we use the formula: \n",
      "Area = Length * Width\n",
      "= 10 * 5\n",
      "= 50 square centimeters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    # Generate an initial draft answer, then iteratively refine it by conditioning each revision on the previous one.\n",
    "    # Step 1: Ask the model to produce the first draft for the given question\n",
    "    # Step 2: Loop for max_steps-1 times, each time feeding the last draft back to the model with a request to revise\n",
    "    # Step 3: Print each draft to observe how the answer evolves\n",
    "    # Step 4: Return the final improved draft\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep your answers clear and correct.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    draft = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    ).choices[0].message.content.strip()\n",
    "    print(f\"Draft 1:\\n{draft}\\n\")\n",
    "\n",
    "    for idx in range(1, max_steps):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Improve answers by making them clearer and more accurate.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": draft},\n",
    "            {\"role\": \"user\", \"content\": \"Please revise your answer. Make it clearer, more accurate, and better written. Only include the new answer.\"}\n",
    "        ]\n",
    "        draft = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0.7\n",
    "        ).choices[0].message.content.strip()\n",
    "        print(f\"Draft {idx + 1}:\\n{draft}\\n\")\n",
    "\n",
    "    return draft\n",
    "\n",
    "output = sequential_revision(\"If a rectangle is twice as long as it is wide and the perimeter is 30 cm, what is the area?\")\n",
    "\n",
    "# Step 1: Define a question that benefits from multi-step reasoning\n",
    "# Step 2: Call sequential_revision(question, max_steps)\n",
    "# Step 3: Print the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    # Generate all valid one-letter mutations of 'word' that exist in 'vocabulary' and return them.\n",
    "    for i, c1 in enumerate(word):\n",
    "        for c2 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            if c1 != c2:\n",
    "                new_word = word[:i] + c2 + word[i+1:]\n",
    "                if new_word in vocabulary: \n",
    "                    yield new_word\n",
    "\n",
    "# vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "# print(list(neighbors(\"hit\", vocab)))\n",
    "# ['lit', 'hot']\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    # Search over partial thoughts (paths) using a small beam.\n",
    "    # Step 1: Initialize the frontier with a single path [start]\n",
    "    # Step 2: For each depth, expand each path by one neighbor from 'neighbors'\n",
    "    # Step 3: Score paths by edit distance between last word and 'goal' (smaller is better)\n",
    "    # Step 4: Keep the top 'beam_width' paths and stop early if any reaches 'goal'\n",
    "    # Step 5: Return the best goal-reaching path or None\n",
    "    frontier = [[start]] # frontier is a list of paths (each path is a list of nodes)\n",
    "    for depth in range(max_depth):\n",
    "        all_candidates = []\n",
    "        for path in frontier:\n",
    "            for nxt in neighbors(path[-1], vocab):\n",
    "                if nxt in path: \n",
    "                    continue \n",
    "                all_candidates.append(path + [nxt])\n",
    "        # score: negative edit distance to goal \n",
    "        scored = sorted(all_candidates, key=lambda p: sum(a!=b for a,b in zip(p[-1], goal)))\n",
    "        frontier = scored[:beam_width]\n",
    "        if any(p[-1] == goal for p in frontier):\n",
    "            return [p for p in frontier if p[-1]==goal][0]\n",
    "    return None \n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab)) # one candidate solution: ['hit', 'hot', 'dot', 'dog', 'cog']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (score 8):\n",
      "Here's a potential next thought to consider:\n",
      "\n",
      "**Nature-Based Science Stations**\n",
      "\n",
      "For the weekend science workshop, I would propose setting up multiple nature-based science stations that cater to different learning styles and interests. Each station could focus on a specific scientific topic, such as:\n",
      "\n",
      "1. Plant Biology: Hands-on experiments with seed germination, plant identification, and composting.\n",
      "2. Environmental Monitoring: Students can conduct water quality tests, measure air temperature and humidity, and learn about the impact of human activities on the ecosystem.\n",
      "3. Animal Habitats: A station where students can observe and learn about local animal species, their habitats, and how to create mini-ecosystems.\n",
      "\n",
      "By breaking down complex scientific concepts into smaller, manageable stations, students will have a more engaging and interactive learning experience. This approach will also allow for flexibility in case some activities are more popular than others, and enable us to adjust the schedule as needed to accommodate all age groups.\n",
      "Here are two potential next thoughts:\n",
      "\n",
      "**1. Incorporating Hands-on STEM Projects**\n",
      "\n",
      "To further enhance the science workshop experience, consider incorporating hands-on STEM (Science, Technology, Engineering, and Math) projects that complement each station. For example:\n",
      "\n",
      "* In the Plant Biology station, students could design and build their own planters using recycled materials and experiment with different growth mediums.\n",
      "* In the Environmental Monitoring station, students could create a simple water filtration system using everyday materials and test its effectiveness.\n",
      "* In the Animal Habitats station, students could design and build a mini-ecosystem using terrariums or glass containers, complete with small plants, rocks, and animals.\n",
      "\n",
      "These hands-on projects will allow students to apply theoretical concepts to real-world problems, develop problem-solving skills, and create something tangible that they can take home as a memento of the workshop.\n",
      "\n",
      "**2. Inclusive Accessibility and Participation**\n",
      "\n",
      "To ensure equal participation for all students, regardless of abilities or learning styles, consider incorporating accessibility features into the planning of each station. For example:\n",
      "\n",
      "* At least one station could be designed with tactile elements, allowing visually impaired students to participate through touch.\n",
      "* Some stations might require students to use assistive technology, such as microscopes or digital tools, which can help students with mobility or dexterity issues participate.\n",
      "* Provide alternative materials or accommodations for students who may have difficulty accessing certain activities due to allergies or sensitivities.\n",
      "\n",
      "By incorporating these inclusivity features, you will ensure that all students feel valued and able to participate fully, contributing to a more equitable and enjoyable science workshop experience.\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def propose_thoughts(question, state, k=2):\n",
    "    # Propose up to k next “thoughts” that extend the current partial solution/state.\n",
    "    # Steps: build a short prompt with problem + current state; call your client with n=k. Then return a list of stripped strings (≤ k).\n",
    "    prompt = f\"\"\"You are exploring solutions.\n",
    "            Problem: {question}\n",
    "            Current partial solution: {state}\n",
    "\n",
    "            Propose at most {k} different next thoughts.\"\"\"\n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.9,\n",
    "        n=k\n",
    "    )\n",
    "    return [c.message.content.strip() for c in r.choices]\n",
    "\n",
    "def score_state(question, state):\n",
    "    # Score how promising a partial solution is on a 1–10 scale (higher is better).\n",
    "    # Steps: build a rating prompt; call the model; parse the first integer 1–10;\n",
    "    prompt = f\"\"\"Problem: {question}\n",
    "        Rate from 1-10 how promising this partial solution is: {state}\"\"\"\n",
    "\n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL, \n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return int(re.findall(r\"\\d+\", r.choices[0].message.content)[0])\n",
    "    except Exception:\n",
    "        return 5 # neutral fallback \n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    # Run a tiny ToT search: expand states with propose_thoughts, score with score_state, keep top-k at each depth.\n",
    "    # Steps: initialize frontier=[(\"\", 0)]; for each depth, expand each state with k=width thoughts; score each; sort by score desc; keep top 'width'; return best state and score.\n",
    "    frontier = [(\"\", 0)]\n",
    "    for _ in range(depth):\n",
    "        new_frontier = []\n",
    "        for state, _ in frontier:\n",
    "            for thought in propose_thoughts(question, state, k=width):\n",
    "                new_state = (state + \"\\n\" + thought).strip()\n",
    "                score = score_state(question, new_state)\n",
    "                new_frontier.append((new_state, score))\n",
    "        new_frontier.sort(key=lambda x: x[1], reverse=True) # keep top-k\n",
    "        frontier = new_frontier[:width] \n",
    "    best_state, best_score = frontier[0]\n",
    "    return best_state, best_score\n",
    "\n",
    "\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question)\n",
    "\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasons and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    # Use DDGS to run a simple web search and return joined snippets.\n",
    "    with DDGS() as ddgs:\n",
    "        results = [hit[\"body\"] for hit in ddgs.text(query, max_results=k)]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/r9jq7k0n0tq744x542jp1jgm0000gn/T/ipykernel_13970/2999904877.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=MODEL, temperature=0.2)\n",
      "/var/folders/nj/r9jq7k0n0tq744x542jp1jgm0000gn/T/ipykernel_13970/2999904877.py:11: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Okay, let's plan for learning Machine Learning by 2025! While I can't predict specific courses or platforms that might emerge, I can focus on foundational resources and learning approaches that are highly likely to remain relevant and effective. The core concepts and skills will be the same, but the *delivery* might evolve slightly.\n",
      "\n",
      "Here are the best *types* of resources and specific examples, keeping 2025 in mind (implying a focus on current and near-future relevant skills):\n",
      "\n",
      "## I. Foundational Concepts & Programming Basics\n",
      "\n",
      "1.  **Online Courses (Beginner-Friendly):**\n",
      "    *   **Coursera / edX (Stanford/MIT/DeepLearning.AI):** Andrew Ng's \"Machine Learning\" (old) and \"AI For Everyone\" (new) are classics. DeepLearning.AI's courses (ML, Deep Learning 1 & 2) are excellent but slightly more advanced. Platforms like Coursera and edX offer structured courses with verified certificates.\n",
      "    *   **Fast.ai:** \"Practical Deep Learning for Coders\" is known for its top-down, code-first approach, making complex concepts accessible quickly. Great for those who prefer learning by doing.\n",
      "    *   **Google's ML Crash Course:** Free, interactive, and covers core ML concepts with a focus on TensorFlow.\n",
      "    *   **Microsoft Learn:** Free, integrated with Azure, offers interactive learning paths for various ML areas.\n",
      "    *   **Kaggle Learn:** Free, interactive courses specifically focused on applying ML with Python and Scikit-learn, often used in competitions.\n",
      "\n",
      "2.  **Introductory Books:**\n",
      "    *   *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron (Updated editions will likely exist in 2025, covering relevant libraries and concepts).\n",
      "    *   *Python Machine Learning* by Sebastian Raschka and Vahid Mirjalili.\n",
      "    *   *Introduction to Machine Learning* by Ethem Alpaydin.\n",
      "\n",
      "## II. Deep Learning (Essential for 2025 AI Trends)\n",
      "\n",
      "1.  **Online Courses:**\n",
      "    *   **DeepLearning.AI Deep Learning Specialization (Coursera):** A series of 5 courses covering Deep Learning fundamentals (Neural Networks, ConvNets, etc.) – *highly recommended*.\n",
      "    *   **Fast.ai (as mentioned above):** Excellent for deep learning fundamentals.\n",
      "    *   **DeepLearning.AI TensorFlow Developer Certificate Program (Coursera):** Focuses specifically on TensorFlow.\n",
      "    *   **DeepLearning.AI PyTorch for Declarative AI (Coursera):** Focuses on PyTorch, another dominant deep learning framework.\n",
      "\n",
      "2.  **Books:**\n",
      "    *   *Deep Learning* by Goodfellow, Bengio, and Courville (The comprehensive textbook, might see updates or companion resources).\n",
      "    *   *Deep Learning with PyTorch and Python* by Eliot Andres.\n",
      "\n",
      "3.  **Frameworks & Tutorials:**\n",
      "    *   **TensorFlow (Google):** Official tutorials, courses, and documentation.\n",
      "    *   **PyTorch (Facebook):** Official tutorials, courses, and documentation.\n",
      "    *   **Hugging Face:** Increasingly central for NLP, offers Transformers course and libraries.\n",
      "\n",
      "## III. Applied Machine Learning & Specific Techniques\n",
      "\n",
      "1.  **Online Platforms:**\n",
      "    *   **Kaggle:** The ultimate platform for hands-on practice, datasets, competitions, and learning from others. Their Learn section is valuable.\n",
      "    *   **DrivenData:** Similar to Kaggle, focused on social good datasets.\n",
      "    *   **DataCamp / Codecademy:** Offer courses on specific ML libraries (like `pandas`, `numpy`, `scikit-learn`) and techniques.\n",
      "\n",
      "2.  **Specific Techniques Courses:**\n",
      "    *   Look for courses focused on NLP (using Transformers), Computer Vision (using CV libraries/Frameworks), Reinforcement Learning, etc., often available on Udacity, Coursera, Udemy, or specialization tracks.\n",
      "\n",
      "## IV. Mathematics & Statistics\n",
      "\n",
      "1.  **Online Courses:**\n",
      "    *   **Coursera / edX:** Look for courses specifically on Linear Algebra, Calculus, Probability, and Statistics relevant to ML. Khan Academy and 3Blue1Brown (YouTube) also offer excellent conceptual explanations.\n",
      "    *   **3Blue1Brown (YouTube):** Great for intuitive understanding of mathematical concepts behind ML.\n",
      "\n",
      "2.  **Books:**\n",
      "    *   *Mathematics for Machine Learning* by Deisenroth, Faisal, and Maatouk (Covers relevant linear algebra, calculus, probability).\n",
      "    *   *Pattern Recognition and Machine Learning* by Bishop (More advanced).\n",
      "\n",
      "## V. Programming & Tools\n",
      "\n",
      "1.  **Python (The lingua franca):** Focus on core Python, data structures, and essential libraries.\n",
      "    *   **Resources:** Official Python docs, Codecademy, Coursera/edX Python courses, Practice with coding challenges (LeetCode, HackerRank).\n",
      "2.  **Key Libraries:**\n",
      "    *   **NumPy:** Scientific computing with Python.\n",
      "    *   **pandas:** Data manipulation and analysis.\n",
      "    *   **Matplotlib / Seaborn:** Data visualization.\n",
      "    *   **scikit-learn:** The workhorse for traditional ML algorithms.\n",
      "    *   **TensorFlow / PyTorch:** For deep learning.\n",
      "\n",
      "## VI. Certifications (Optional but Valuable)\n",
      "\n",
      "*   Look for vendor-specific certifications (e.g., Azure AI, Google Cloud AI, AWS Machine Learning) or specialized certifications from providers like Coursera/edX/LinkedIn.\n",
      "\n",
      "## VII. Communities & Following Research\n",
      "\n",
      "*   **Follow key researchers and companies on Twitter, LinkedIn, and GitHub.**\n",
      "*   **Read blogs:** Google AI Blog, OpenAI Blog, Facebook AI Blog, Kaggle Blog, Towards Data Science, Distill.\n",
      "*   **Subscribe to academic journals/conferences (like NeurIPS, ICML, ICASSP - might have virtual access).**\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Emphasis on LLMs & NLP:** Expect even more focus on courses and resources covering Large Language Models and advanced NLP techniques using Transformers.\n",
      "*   **MLOps:** Understanding deployment, monitoring, and scaling ML models will become increasingly important.\n",
      "*   **Ethics & Responsible AI:** More courses and discussions around the societal impact of AI.\n",
      "*   **Cloud Platforms:** Continued importance of learning ML on platforms like AWS, Azure, and GCP.\n",
      "*   **Interpretability & Explainability:** Growing need to understand *why* models make decisions.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "Start with foundational courses (Coursera/edX/Google/MLCC), get comfortable with Python and `scikit-learn`, then move into Deep Learning (Fast.ai/DeepLearning.AI). Supplement with Kaggle for hands-on practice and stay updated by following research and communities. Good luck!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Final answer: \n",
      "Okay, let's plan for learning Machine Learning by 2025! While I can't predict specific courses or platforms that might emerge, I can focus on foundational resources and learning approaches that are highly likely to remain relevant and effective. The core concepts and skills will be the same, but the *delivery* might evolve slightly.\n",
      "\n",
      "Here are the best *types* of resources and specific examples, keeping 2025 in mind (implying a focus on current and near-future relevant skills):\n",
      "\n",
      "## I. Foundational Concepts & Programming Basics\n",
      "\n",
      "1.  **Online Courses (Beginner-Friendly):**\n",
      "    *   **Coursera / edX (Stanford/MIT/DeepLearning.AI):** Andrew Ng's \"Machine Learning\" (old) and \"AI For Everyone\" (new) are classics. DeepLearning.AI's courses (ML, Deep Learning 1 & 2) are excellent but slightly more advanced. Platforms like Coursera and edX offer structured courses with verified certificates.\n",
      "    *   **Fast.ai:** \"Practical Deep Learning for Coders\" is known for its top-down, code-first approach, making complex concepts accessible quickly. Great for those who prefer learning by doing.\n",
      "    *   **Google's ML Crash Course:** Free, interactive, and covers core ML concepts with a focus on TensorFlow.\n",
      "    *   **Microsoft Learn:** Free, integrated with Azure, offers interactive learning paths for various ML areas.\n",
      "    *   **Kaggle Learn:** Free, interactive courses specifically focused on applying ML with Python and Scikit-learn, often used in competitions.\n",
      "\n",
      "2.  **Introductory Books:**\n",
      "    *   *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron (Updated editions will likely exist in 2025, covering relevant libraries and concepts).\n",
      "    *   *Python Machine Learning* by Sebastian Raschka and Vahid Mirjalili.\n",
      "    *   *Introduction to Machine Learning* by Ethem Alpaydin.\n",
      "\n",
      "## II. Deep Learning (Essential for 2025 AI Trends)\n",
      "\n",
      "1.  **Online Courses:**\n",
      "    *   **DeepLearning.AI Deep Learning Specialization (Coursera):** A series of 5 courses covering Deep Learning fundamentals (Neural Networks, ConvNets, etc.) – *highly recommended*.\n",
      "    *   **Fast.ai (as mentioned above):** Excellent for deep learning fundamentals.\n",
      "    *   **DeepLearning.AI TensorFlow Developer Certificate Program (Coursera):** Focuses specifically on TensorFlow.\n",
      "    *   **DeepLearning.AI PyTorch for Declarative AI (Coursera):** Focuses on PyTorch, another dominant deep learning framework.\n",
      "\n",
      "2.  **Books:**\n",
      "    *   *Deep Learning* by Goodfellow, Bengio, and Courville (The comprehensive textbook, might see updates or companion resources).\n",
      "    *   *Deep Learning with PyTorch and Python* by Eliot Andres.\n",
      "\n",
      "3.  **Frameworks & Tutorials:**\n",
      "    *   **TensorFlow (Google):** Official tutorials, courses, and documentation.\n",
      "    *   **PyTorch (Facebook):** Official tutorials, courses, and documentation.\n",
      "    *   **Hugging Face:** Increasingly central for NLP, offers Transformers course and libraries.\n",
      "\n",
      "## III. Applied Machine Learning & Specific Techniques\n",
      "\n",
      "1.  **Online Platforms:**\n",
      "    *   **Kaggle:** The ultimate platform for hands-on practice, datasets, competitions, and learning from others. Their Learn section is valuable.\n",
      "    *   **DrivenData:** Similar to Kaggle, focused on social good datasets.\n",
      "    *   **DataCamp / Codecademy:** Offer courses on specific ML libraries (like `pandas`, `numpy`, `scikit-learn`) and techniques.\n",
      "\n",
      "2.  **Specific Techniques Courses:**\n",
      "    *   Look for courses focused on NLP (using Transformers), Computer Vision (using CV libraries/Frameworks), Reinforcement Learning, etc., often available on Udacity, Coursera, Udemy, or specialization tracks.\n",
      "\n",
      "## IV. Mathematics & Statistics\n",
      "\n",
      "1.  **Online Courses:**\n",
      "    *   **Coursera / edX:** Look for courses specifically on Linear Algebra, Calculus, Probability, and Statistics relevant to ML. Khan Academy and 3Blue1Brown (YouTube) also offer excellent conceptual explanations.\n",
      "    *   **3Blue1Brown (YouTube):** Great for intuitive understanding of mathematical concepts behind ML.\n",
      "\n",
      "2.  **Books:**\n",
      "    *   *Mathematics for Machine Learning* by Deisenroth, Faisal, and Maatouk (Covers relevant linear algebra, calculus, probability).\n",
      "    *   *Pattern Recognition and Machine Learning* by Bishop (More advanced).\n",
      "\n",
      "## V. Programming & Tools\n",
      "\n",
      "1.  **Python (The lingua franca):** Focus on core Python, data structures, and essential libraries.\n",
      "    *   **Resources:** Official Python docs, Codecademy, Coursera/edX Python courses, Practice with coding challenges (LeetCode, HackerRank).\n",
      "2.  **Key Libraries:**\n",
      "    *   **NumPy:** Scientific computing with Python.\n",
      "    *   **pandas:** Data manipulation and analysis.\n",
      "    *   **Matplotlib / Seaborn:** Data visualization.\n",
      "    *   **scikit-learn:** The workhorse for traditional ML algorithms.\n",
      "    *   **TensorFlow / PyTorch:** For deep learning.\n",
      "\n",
      "## VI. Certifications (Optional but Valuable)\n",
      "\n",
      "*   Look for vendor-specific certifications (e.g., Azure AI, Google Cloud AI, AWS Machine Learning) or specialized certifications from providers like Coursera/edX/LinkedIn.\n",
      "\n",
      "## VII. Communities & Following Research\n",
      "\n",
      "*   **Follow key researchers and companies on Twitter, LinkedIn, and GitHub.**\n",
      "*   **Read blogs:** Google AI Blog, OpenAI Blog, Facebook AI Blog, Kaggle Blog, Towards Data Science, Distill.\n",
      "*   **Subscribe to academic journals/conferences (like NeurIPS, ICML, ICASSP - might have virtual access).**\n",
      "\n",
      "## Key Considerations for 2025\n",
      "\n",
      "*   **Emphasis on LLMs & NLP:** Expect even more focus on courses and resources covering Large Language Models and advanced NLP techniques using Transformers.\n",
      "*   **MLOps:** Understanding deployment, monitoring, and scaling ML models will become increasingly important.\n",
      "*   **Ethics & Responsible AI:** More courses and discussions around the societal impact of AI.\n",
      "*   **Cloud Platforms:** Continued importance of learning ML on platforms like AWS, Azure, and GCP.\n",
      "*   **Interpretability & Explainability:** Growing need to understand *why* models make decisions.\n",
      "\n",
      "## Recommendation\n",
      "\n",
      "Start with foundational courses (Coursera/edX/Google/MLCC), get comfortable with Python and `scikit-learn`, then move into Deep Learning (Fast.ai/DeepLearning.AI). Supplement with Kaggle for hands-on practice and stay updated by following research and communities. Good luck!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "llm = ChatOllama(model=MODEL, temperature=0.2)\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "agent = initialize_agent(\n",
    "    tools=[search_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "result = agent.invoke({\"input\": question})\n",
    "print(\"Final answer:\", result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "    \n",
    "    \"\"\"\n",
    "    YOUR CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "answers = parallel_research(\"What are the best resources to learn ML in 2025?\")\n",
    "for i,a in enumerate(answers,1):\n",
    "    print(f\"[Run {i}] {a[:200]}…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "deep_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
